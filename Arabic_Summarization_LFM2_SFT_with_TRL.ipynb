{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3PTFH-H9Ozk"
   },
   "source": [
    "# 💧 LFM2 - SFT with TRL\n",
    "\n",
    "This tutorial demonstrates how to fine-tune our LFM2 models, e.g. [`LiquidAI/LFM2-1.2B`](https://huggingface.co/LiquidAI/LFM2-1.2B), using the TRL library.\n",
    "\n",
    "Follow along if it's your first time using trl, or take single code snippets for your own workflow\n",
    "\n",
    "## 🎯 What you'll find:\n",
    "- **SFT** (Supervised Fine-Tuning) - Basic instruction following\n",
    "- **LoRA + SFT** - Using LoRA (from PEFT) to SFT while on constrained hardware\n",
    "\n",
    "## 📋 Prerequisites:\n",
    "- **GPU Runtime**: Select GPU in `Runtime` → `Change runtime type`\n",
    "- **Hugging Face Account**: For accessing models and datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0RPLu2h9ome"
   },
   "source": [
    "# 📦 Installation & Setup\n",
    "\n",
    "First, let's install all the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FIcp_wo9nsR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.54.1 trl>=0.18.2 peft>=0.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install patchelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!patchelf --add-rpath '$ORIGIN/../../nvidia/cusparse/lib' /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41UEf1uxCd6m"
   },
   "source": [
    "Let's now verify the packages are installed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSJgYtHT_Os4",
    "outputId": "23f86c62-471c-4579-fc23-1df88e87698b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import trl\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "print(f\"📦 PyTorch version: {torch.__version__}\")\n",
    "print(f\"🤗 Transformers version: {transformers.__version__}\")\n",
    "print(f\"📊 TRL version: {trl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_uXLzxQ_rnK"
   },
   "source": [
    "# Loading the model from Transformers 🤗\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iA3erKM4-HhS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Loading tokenizer...\n",
      "🧠 Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.11/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-08-19 00:26:28.995179: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-19 00:26:29.033924: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-19 00:26:29.033969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-19 00:26:29.035101: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-19 00:26:29.042173: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-19 00:26:29.962824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Local model loaded successfully!\n",
      "🔢 Parameters: 354,483,968\n",
      "📖 Vocab size: 64400\n",
      "💾 Model size: ~0.7 GB (bfloat16)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import torch\n",
    "\n",
    "model_id = \"LiquidAI/LFM2-350M\" # <- or LFM2-700M or LFM2-350M\n",
    "\n",
    "print(\"📚 Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(\"🧠 Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"bfloat16\",\n",
    "#   attn_implementation=\"flash_attention_2\" <- uncomment on compatible GPU\n",
    ")\n",
    "\n",
    "print(\"✅ Local model loaded successfully!\")\n",
    "print(f\"🔢 Parameters: {model.num_parameters():,}\")\n",
    "print(f\"📖 Vocab size: {len(tokenizer)}\")\n",
    "print(f\"💾 Model size: ~{model.num_parameters() * 2 / 1e9:.1f} GB (bfloat16)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ABA6Yrm_lql"
   },
   "source": [
    "# 🎯 Part 1: Supervised Fine-Tuning (SFT)\n",
    "\n",
    "SFT teaches the model to follow instructions by training on input-output pairs (instruction vs response). This is the foundation for creating instruction-following models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KufdgeypHtst"
   },
   "source": [
    "## Load an SFT Dataset\n",
    "\n",
    "We will use [HuggingFaceTB/smoltalk](https://huggingface.co/datasets/HuggingFaceTB/smoltalk), limiting ourselves to the first 5k samples for brevity. Feel free to change the limit by changing the slicing index in the parameter `split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XCe8O06-_Cps",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading SFT dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f49b719f5f4528bebae99c4c81ae18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/716 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f5230f2b4341a29b74697578722896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/92.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b97ee6327f446718d444df1e8854ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/928k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b95e6f022b416aa8011112366811d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813d3db99d7a4d06b7f65ea8512f8095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd9f894c8184189bcfcb53b6e9fcf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d2ff96d0ba4d7eba593847ec10957d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be362032b9b041b0b891894ff43e1f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e634f73d4f472f898fb072ac479ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SFT Dataset loaded:\n",
      "   📚 Train samples: 17862\n",
      "   🧪 Eval samples: 181\n",
      "\n",
      "📝 Single Sample: [{'content': 'Summarize the following text: \\n\\n بقلم: وليام تورفيل. نشر في: 08:04 صباحًا بتوقيت شرق الولايات المتحدة، 21 ديسمبر 2013 | تم تحديثه: 09:07 صباحًا بتوقيت شرق الولايات المتحدة، 21 ديسمبر 2013. إذا كنت تدخل في الروح المناسبة لعيد الميلاد بمجرد سماع أغنية عيد الميلاد أو رؤية صفوف من الزخارف للبيع، فمن الأفضل أن تبتعد عن هذه الشوارع. قد تبدو شوارع مثل تينسيل لين في نونيتون، وارويكشاير، غريبة في الصيف - لكنها تأخذ مكانها في ديسمبر. وجد بحث موظفي رويال ميل أن المملكة المتحدة لديها 3369 اسمًا لشوارع مرتبطة بعيد الميلاد، بناءً على تحليل كل اسم شارع في البلاد. تينسيل لين في نونيتون، وارويكشاير، مزينة هذا العام من قبل السكان ميشيل أورتون وابنها ذي الثلاث سنوات، ماثيو. تعرض الأخوات نيام ديفي (على اليسار)، البالغة من العمر ثماني سنوات، وسيارا ديفي، البالغة من العمر خمس سنوات، أمام اسم شارعهم - الذي قد يبدو غريبًا بعض الشيء في الصيف - في نورثامبتون. هولي ستريت هي أكثر الأسماء شيوعًا لشوارع عيد الميلاد في المملكة المتحدة. هناك 990 اسمًا لهذا النوع من الشوارع في جميع أنحاء المملكة المتحدة. 1. شارع هولي. 2. شارع بيل. 3. شارع ماري. 4. شارع إنجل. 5. طريق ستار. 6. شارع بو. 7. ساحة فيستيفال. 8. شارع نويل. 9. شارع غولد. 10. شارع غارلاند. كشف البحث أيضًا أن إقليم ميدلاندز لديه ما مجموعه 560 اسمًا لشوارع عيد الميلاد، أكثر من أي منطقة أخرى في المملكة المتحدة. تحتوي المنطقة على ما مجموعه 560 اسمًا لشوارع عيد الميلاد وتتمتع بأسماء شوارع مناسبة لعيد الميلاد مثل ريندير رود، ونويل رود، وبيل كلوز، وهولي ستريت. التقييمات جاءت من تحليل قاعدة بيانات رويال ميل التي تحتوي على 29 مليون عنوان في المملكة المتحدة. تكشف قاعدة البيانات أيضًا عن حبنا لرنود سانتا، حيث أن سبعة من تسعة رنود ممثلة في اسم شارع. وتشمل هذه: داشر، ودانسر، وفيكسن، وكوميت، وكيوبيد، ودونر، ورودولف. سكان تينسيل لين في نونيتون، نورثامبتون، بذلوا جهدًا كبيرًا هذا العام من خلال تزيين لافتتهم مثل شجرة الميلاد. قدم ماثيو البالغ من العمر ثلاث سنوات وأمه ميشيل أورتون بالفعل لتزيين لافتة شارعهم. في غضون ذلك، سيكون فريستي هولو في نورثامبتون عنصر جذب كبير للصور الفوتوغرافية خلال هذا الشهر. ويبدو أن الأخوات نيام ديفي، البالغة من العمر ثماني سنوات، وسيارا، البالغة من العمر خمس سنوات، قد فازتا على أصدقائهما. شارع نويل، في إيلينج، لندن الغربية، يتطلب القليل من الخيال لكنه لا يزال يمكن اعتباره شارعًا يبدو مناسبًا جدًا لعيد الميلاد، إذا نطقت بشكل صحيح. ريندير كلوز أكثر وضوحًا، وسيكون من المؤكد أن سكان شرق لندن في حالة مزاجية لعيد الميلاد بحلول ديسمبر. أربع سنوات من السن بوبي جروت تلتقط صورة مع جدتها جين لونج بالقرب من ميستل تو غرين في أكسفورد. ومع ذلك، على أساس الأدلة الفوتوغرافية، لا يبدو أن المرح أكبر في لندن، حيث أن اللافتات المناسبة لعيد الميلاد أكثر شيوعًا ويتم التعامل معها بقليل من الحماس. بعض اللافتات المصورة مثل نويل رود، التي تتطلب نطقًا خاصًا، وستار رود. لكن في حالات أخرى - ريندير كلوز وهولي واي - لا يمكن الهروب من المعنى المسيحي للأسماء. قد يجذب ستريت توركيل الناس في نورث إنجلاند إلى عيد الميلاد، لكن عليهم أن يسافروا إلى تاور هاملتس لإيجاد كرانبري لين. فريستي يارد في مدينة ويستمنستر، لندن، توفر اسمًا مناسبًا لعيد الميلاد مع خلفية أكثر توراتية. يجب على أولئك الذين لا يستمتعون بعيد الميلاد أن يبتعدوا عن هذه الشوارع. وبالمثل، إذا كنت لا تشعر بالرغبة في قبلة عيد الميلاد، فتعلم من أخطاء بوبي جروت البالغة من العمر أربع سنوات، التي اشتعلت وهي تلتقط صورة مع جدتها، جين لونج، أمام ميستل غرين في أكسفورد. بالنسبة لسكان أدفنت واي، ديسمبر لا يمكن أن يأتي بسرعة كافية. على الرغم من كل شيء، لا يوجد في نويسلين في نورثلينكولن، إلينج، شارع مناسب لعيد الميلاد .', 'role': 'user'}, {'content': 'وجد بحث أجراه موظفو \"رويال ميل\" العام الماضي أن المملكة المتحدة لديها 3369 اسمًا لشوارع مُوَضوعها الميلاد. ويعد \"هولي ستريت\" أكثر أسماء الشوارع احتفالية شيوعًا في المملكة المتحدة. هناك 990 اسمًا لشوارع من هذا النوع في جميع أنحاء المملكة المتحدة.', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"📥 Loading SFT dataset...\")\n",
    "train_dataset_sft = load_dataset(\"oddadmix/arabic-news-summarization\", split=\"train\")\n",
    "eval_dataset_sft = load_dataset(\"oddadmix/arabic-news-summarization\", split=\"test\")\n",
    "\n",
    "\n",
    "def filterEmpty(example):\n",
    "    if example[\"summary_text_translated\"] is None or example[\"origin_text_translated\"] is None: \n",
    "        return False\n",
    "    return True\n",
    "\n",
    "train_dataset_sft = train_dataset_sft.filter(filterEmpty)\n",
    "eval_dataset_sft = eval_dataset_sft.filter(filterEmpty)\n",
    "\n",
    "\n",
    "def convert_to_conversation(example):\n",
    "    example[\"messages\"] = [\n",
    "        {\n",
    "        \"content\": \"Summarize the following text: \\n\\n \" + example[\"origin_text_translated\"] ,\n",
    "        \"role\": \"user\"\n",
    "        },\n",
    "        {\n",
    "        \"content\": example[\"summary_text_translated\"],\n",
    "        \"role\": \"assistant\"\n",
    "        }\n",
    "        ]\n",
    "    return example\n",
    "\n",
    "train_dataset_sft = train_dataset_sft.map(convert_to_conversation, remove_columns=[\"origin_text_translated\", \"origin_text\", \"summary_text_translated\",\"summary_text\"])\n",
    "eval_dataset_sft = eval_dataset_sft.map(convert_to_conversation, remove_columns=[\"origin_text_translated\", \"origin_text\", \"summary_text_translated\",\"summary_text\"])\n",
    "\n",
    "print(\"✅ SFT Dataset loaded:\")\n",
    "print(f\"   📚 Train samples: {len(train_dataset_sft)}\")\n",
    "print(f\"   🧪 Eval samples: {len(eval_dataset_sft)}\")\n",
    "print(f\"\\n📝 Single Sample: {train_dataset_sft[0]['messages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5pI5JWpIlFQ"
   },
   "source": [
    "## Launch Training\n",
    "\n",
    "We are now ready to launch an SFT run with `SFTTrainer`, feel free to modify `SFTConfig` to play around with different configurations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixD8Po-eAbPp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️  Creating SFT trainer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfa2b44e9cc4428bb62a6a39e817602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25baa87e24c241cc886483fef226acd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a65ade53ce04f6cb1300e614b8be2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bd5a17940f4ad0a3c323fc58c961cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-19 00:27:18,883] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\n",
      "🚀 Starting SFT training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahmed-m-wasfy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/Translations/wandb/run-20250819_002721-cl4p100g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahmed-m-wasfy/huggingface/runs/cl4p100g' target=\"_blank\">./lfm2-sft-summary</a></strong> to <a href='https://wandb.ai/ahmed-m-wasfy/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahmed-m-wasfy/huggingface' target=\"_blank\">https://wandb.ai/ahmed-m-wasfy/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahmed-m-wasfy/huggingface/runs/cl4p100g' target=\"_blank\">https://wandb.ai/ahmed-m-wasfy/huggingface/runs/cl4p100g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4697' max='11170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4697/11170 02:42 < 1:17:21, 1.39 it/s, Epoch 4.20/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./lfm2-sft-summary\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=100,\n",
    "    warmup_ratio=0.2,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=None,\n",
    "    bf16=False # <- not all colab GPUs support bf16\n",
    ")\n",
    "\n",
    "print(\"🏗️  Creating SFT trainer...\")\n",
    "sft_trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_dataset_sft,\n",
    "    eval_dataset=eval_dataset_sft,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"\\n🚀 Starting SFT training...\")\n",
    "sft_trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "print(\"🎉 SFT training completed!\")\n",
    "\n",
    "sft_trainer.push_to_hub(\"oddadmix/arabic-summarization\")\n",
    "#sft_trainer.save_model()\n",
    "print(f\"💾 SFT model saved to: {sft_config.output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
