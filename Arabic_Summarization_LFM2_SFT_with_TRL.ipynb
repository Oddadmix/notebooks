{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3PTFH-H9Ozk"
      },
      "source": [
        "# ðŸ’§ LFM2 - SFT with TRL\n",
        "\n",
        "This tutorial demonstrates how to fine-tune our LFM2 models, e.g. [`LiquidAI/LFM2-1.2B`](https://huggingface.co/LiquidAI/LFM2-1.2B), using the TRL library.\n",
        "\n",
        "Follow along if it's your first time using trl, or take single code snippets for your own workflow\n",
        "\n",
        "## ðŸŽ¯ What you'll find:\n",
        "- **SFT** (Supervised Fine-Tuning) - Basic instruction following\n",
        "- **LoRA + SFT** - Using LoRA (from PEFT) to SFT while on constrained hardware\n",
        "\n",
        "## ðŸ“‹ Prerequisites:\n",
        "- **GPU Runtime**: Select GPU in `Runtime` â†’ `Change runtime type`\n",
        "- **Hugging Face Account**: For accessing models and datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0RPLu2h9ome"
      },
      "source": [
        "# ðŸ“¦ Installation & Setup\n",
        "\n",
        "First, let's install all the required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3FIcp_wo9nsR",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.54.1 trl>=0.18.2 peft>=0.15.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8qlnEnVvQFg",
        "outputId": "7ef6c308-43a0-43cc-f12d-c9029d496ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "P7hBRIbavQFg"
      },
      "outputs": [],
      "source": [
        "#!pip install patchelf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "id": "yOkmAj03vQFg"
      },
      "outputs": [],
      "source": [
        "#!patchelf --add-rpath '$ORIGIN/../../nvidia/cusparse/lib' /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41UEf1uxCd6m"
      },
      "source": [
        "Let's now verify the packages are installed correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSJgYtHT_Os4",
        "outputId": "75f22ad0-e52f-4643-8949-d1df27c93bf9",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ PyTorch version: 2.6.0+cu124\n",
            "ðŸ¤— Transformers version: 4.54.1\n",
            "ðŸ“Š TRL version: 0.20.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import trl\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "print(f\"ðŸ“¦ PyTorch version: {torch.__version__}\")\n",
        "print(f\"ðŸ¤— Transformers version: {transformers.__version__}\")\n",
        "print(f\"ðŸ“Š TRL version: {trl.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_uXLzxQ_rnK"
      },
      "source": [
        "# Loading the model from Transformers ðŸ¤—\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iA3erKM4-HhS",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c56377-ec22-4c58-a18e-b5c745987181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“š Loading tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Loading model...\n",
            "âœ… Local model loaded successfully!\n",
            "ðŸ”¢ Parameters: 354,483,968\n",
            "ðŸ“– Vocab size: 64400\n",
            "ðŸ’¾ Model size: ~0.7 GB (bfloat16)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import torch\n",
        "\n",
        "model_id = \"LiquidAI/LFM2-350M\" # <- or LFM2-700M or LFM2-350M\n",
        "\n",
        "print(\"ðŸ“š Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "print(\"ðŸ§  Loading model...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"bfloat16\",\n",
        "#   attn_implementation=\"flash_attention_2\" <- uncomment on compatible GPU\n",
        ")\n",
        "\n",
        "print(\"âœ… Local model loaded successfully!\")\n",
        "print(f\"ðŸ”¢ Parameters: {model.num_parameters():,}\")\n",
        "print(f\"ðŸ“– Vocab size: {len(tokenizer)}\")\n",
        "print(f\"ðŸ’¾ Model size: ~{model.num_parameters() * 2 / 1e9:.1f} GB (bfloat16)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ABA6Yrm_lql"
      },
      "source": [
        "# ðŸŽ¯ Part 1: Supervised Fine-Tuning (SFT)\n",
        "\n",
        "SFT teaches the model to follow instructions by training on input-output pairs (instruction vs response). This is the foundation for creating instruction-following models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KufdgeypHtst"
      },
      "source": [
        "## Load an SFT Dataset\n",
        "\n",
        "We will use [HuggingFaceTB/smoltalk](https://huggingface.co/datasets/HuggingFaceTB/smoltalk), limiting ourselves to the first 5k samples for brevity. Feel free to change the limit by changing the slicing index in the parameter `split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XCe8O06-_Cps",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b24d106-93ab-46a2-c967-9110d7d07561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading SFT dataset...\n",
            "âœ… SFT Dataset loaded:\n",
            "   ðŸ“š Train samples: 17862\n",
            "   ðŸ§ª Eval samples: 181\n",
            "\n",
            "ðŸ“ Single Sample: [{'content': 'Summarize the following text: \\n\\n Ø¨Ù‚Ù„Ù…: ÙˆÙ„ÙŠØ§Ù… ØªÙˆØ±ÙÙŠÙ„. Ù†Ø´Ø± ÙÙŠ: 08:04 ØµØ¨Ø§Ø­Ù‹Ø§ Ø¨ØªÙˆÙ‚ÙŠØª Ø´Ø±Ù‚ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©ØŒ 21 Ø¯ÙŠØ³Ù…Ø¨Ø± 2013 | ØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡: 09:07 ØµØ¨Ø§Ø­Ù‹Ø§ Ø¨ØªÙˆÙ‚ÙŠØª Ø´Ø±Ù‚ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©ØŒ 21 Ø¯ÙŠØ³Ù…Ø¨Ø± 2013. Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¯Ø®Ù„ ÙÙŠ Ø§Ù„Ø±ÙˆØ­ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø¨Ù…Ø¬Ø±Ø¯ Ø³Ù…Ø§Ø¹ Ø£ØºÙ†ÙŠØ© Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø£Ùˆ Ø±Ø¤ÙŠØ© ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ø²Ø®Ø§Ø±Ù Ù„Ù„Ø¨ÙŠØ¹ØŒ ÙÙ…Ù† Ø§Ù„Ø£ÙØ¶Ù„ Ø£Ù† ØªØ¨ØªØ¹Ø¯ Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø´ÙˆØ§Ø±Ø¹. Ù‚Ø¯ ØªØ¨Ø¯Ùˆ Ø´ÙˆØ§Ø±Ø¹ Ù…Ø«Ù„ ØªÙŠÙ†Ø³ÙŠÙ„ Ù„ÙŠÙ† ÙÙŠ Ù†ÙˆÙ†ÙŠØªÙˆÙ†ØŒ ÙˆØ§Ø±ÙˆÙŠÙƒØ´Ø§ÙŠØ±ØŒ ØºØ±ÙŠØ¨Ø© ÙÙŠ Ø§Ù„ØµÙŠÙ - Ù„ÙƒÙ†Ù‡Ø§ ØªØ£Ø®Ø° Ù…ÙƒØ§Ù†Ù‡Ø§ ÙÙŠ Ø¯ÙŠØ³Ù…Ø¨Ø±. ÙˆØ¬Ø¯ Ø¨Ø­Ø« Ù…ÙˆØ¸ÙÙŠ Ø±ÙˆÙŠØ§Ù„ Ù…ÙŠÙ„ Ø£Ù† Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø© Ù„Ø¯ÙŠÙ‡Ø§ 3369 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ø§Ø³Ù… Ø´Ø§Ø±Ø¹ ÙÙŠ Ø§Ù„Ø¨Ù„Ø§Ø¯. ØªÙŠÙ†Ø³ÙŠÙ„ Ù„ÙŠÙ† ÙÙŠ Ù†ÙˆÙ†ÙŠØªÙˆÙ†ØŒ ÙˆØ§Ø±ÙˆÙŠÙƒØ´Ø§ÙŠØ±ØŒ Ù…Ø²ÙŠÙ†Ø© Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ø³ÙƒØ§Ù† Ù…ÙŠØ´ÙŠÙ„ Ø£ÙˆØ±ØªÙˆÙ† ÙˆØ§Ø¨Ù†Ù‡Ø§ Ø°ÙŠ Ø§Ù„Ø«Ù„Ø§Ø« Ø³Ù†ÙˆØ§ØªØŒ Ù…Ø§Ø«ÙŠÙˆ. ØªØ¹Ø±Ø¶ Ø§Ù„Ø£Ø®ÙˆØ§Øª Ù†ÙŠØ§Ù… Ø¯ÙŠÙÙŠ (Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±)ØŒ Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø«Ù…Ø§Ù†ÙŠ Ø³Ù†ÙˆØ§ØªØŒ ÙˆØ³ÙŠØ§Ø±Ø§ Ø¯ÙŠÙÙŠØŒ Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø®Ù…Ø³ Ø³Ù†ÙˆØ§ØªØŒ Ø£Ù…Ø§Ù… Ø§Ø³Ù… Ø´Ø§Ø±Ø¹Ù‡Ù… - Ø§Ù„Ø°ÙŠ Ù‚Ø¯ ÙŠØ¨Ø¯Ùˆ ØºØ±ÙŠØ¨Ù‹Ø§ Ø¨Ø¹Ø¶ Ø§Ù„Ø´ÙŠØ¡ ÙÙŠ Ø§Ù„ØµÙŠÙ - ÙÙŠ Ù†ÙˆØ±Ø«Ø§Ù…Ø¨ØªÙˆÙ†. Ù‡ÙˆÙ„ÙŠ Ø³ØªØ±ÙŠØª Ù‡ÙŠ Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø´ÙŠÙˆØ¹Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. Ù‡Ù†Ø§Ùƒ 990 Ø§Ø³Ù…Ù‹Ø§ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ø´ÙˆØ§Ø±Ø¹ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. 1. Ø´Ø§Ø±Ø¹ Ù‡ÙˆÙ„ÙŠ. 2. Ø´Ø§Ø±Ø¹ Ø¨ÙŠÙ„. 3. Ø´Ø§Ø±Ø¹ Ù…Ø§Ø±ÙŠ. 4. Ø´Ø§Ø±Ø¹ Ø¥Ù†Ø¬Ù„. 5. Ø·Ø±ÙŠÙ‚ Ø³ØªØ§Ø±. 6. Ø´Ø§Ø±Ø¹ Ø¨Ùˆ. 7. Ø³Ø§Ø­Ø© ÙÙŠØ³ØªÙŠÙØ§Ù„. 8. Ø´Ø§Ø±Ø¹ Ù†ÙˆÙŠÙ„. 9. Ø´Ø§Ø±Ø¹ ØºÙˆÙ„Ø¯. 10. Ø´Ø§Ø±Ø¹ ØºØ§Ø±Ù„Ø§Ù†Ø¯. ÙƒØ´Ù Ø§Ù„Ø¨Ø­Ø« Ø£ÙŠØ¶Ù‹Ø§ Ø£Ù† Ø¥Ù‚Ù„ÙŠÙ… Ù…ÙŠØ¯Ù„Ø§Ù†Ø¯Ø² Ù„Ø¯ÙŠÙ‡ Ù…Ø§ Ù…Ø¬Ù…ÙˆØ¹Ù‡ 560 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ø£ÙƒØ«Ø± Ù…Ù† Ø£ÙŠ Ù…Ù†Ø·Ù‚Ø© Ø£Ø®Ø±Ù‰ ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. ØªØ­ØªÙˆÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø§ Ù…Ø¬Ù…ÙˆØ¹Ù‡ 560 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ ÙˆØªØªÙ…ØªØ¹ Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø´ÙˆØ§Ø±Ø¹ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ù…Ø«Ù„ Ø±ÙŠÙ†Ø¯ÙŠØ± Ø±ÙˆØ¯ØŒ ÙˆÙ†ÙˆÙŠÙ„ Ø±ÙˆØ¯ØŒ ÙˆØ¨ÙŠÙ„ ÙƒÙ„ÙˆØ²ØŒ ÙˆÙ‡ÙˆÙ„ÙŠ Ø³ØªØ±ÙŠØª. Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø¬Ø§Ø¡Øª Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø±ÙˆÙŠØ§Ù„ Ù…ÙŠÙ„ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 29 Ù…Ù„ÙŠÙˆÙ† Ø¹Ù†ÙˆØ§Ù† ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. ØªÙƒØ´Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙŠØ¶Ù‹Ø§ Ø¹Ù† Ø­Ø¨Ù†Ø§ Ù„Ø±Ù†ÙˆØ¯ Ø³Ø§Ù†ØªØ§ØŒ Ø­ÙŠØ« Ø£Ù† Ø³Ø¨Ø¹Ø© Ù…Ù† ØªØ³Ø¹Ø© Ø±Ù†ÙˆØ¯ Ù…Ù…Ø«Ù„Ø© ÙÙŠ Ø§Ø³Ù… Ø´Ø§Ø±Ø¹. ÙˆØªØ´Ù…Ù„ Ù‡Ø°Ù‡: Ø¯Ø§Ø´Ø±ØŒ ÙˆØ¯Ø§Ù†Ø³Ø±ØŒ ÙˆÙÙŠÙƒØ³Ù†ØŒ ÙˆÙƒÙˆÙ…ÙŠØªØŒ ÙˆÙƒÙŠÙˆØ¨ÙŠØ¯ØŒ ÙˆØ¯ÙˆÙ†Ø±ØŒ ÙˆØ±ÙˆØ¯ÙˆÙ„Ù. Ø³ÙƒØ§Ù† ØªÙŠÙ†Ø³ÙŠÙ„ Ù„ÙŠÙ† ÙÙŠ Ù†ÙˆÙ†ÙŠØªÙˆÙ†ØŒ Ù†ÙˆØ±Ø«Ø§Ù…Ø¨ØªÙˆÙ†ØŒ Ø¨Ø°Ù„ÙˆØ§ Ø¬Ù‡Ø¯Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ²ÙŠÙŠÙ† Ù„Ø§ÙØªØªÙ‡Ù… Ù…Ø«Ù„ Ø´Ø¬Ø±Ø© Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯. Ù‚Ø¯Ù… Ù…Ø§Ø«ÙŠÙˆ Ø§Ù„Ø¨Ø§Ù„Øº Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø«Ù„Ø§Ø« Ø³Ù†ÙˆØ§Øª ÙˆØ£Ù…Ù‡ Ù…ÙŠØ´ÙŠÙ„ Ø£ÙˆØ±ØªÙˆÙ† Ø¨Ø§Ù„ÙØ¹Ù„ Ù„ØªØ²ÙŠÙŠÙ† Ù„Ø§ÙØªØ© Ø´Ø§Ø±Ø¹Ù‡Ù…. ÙÙŠ ØºØ¶ÙˆÙ† Ø°Ù„ÙƒØŒ Ø³ÙŠÙƒÙˆÙ† ÙØ±ÙŠØ³ØªÙŠ Ù‡ÙˆÙ„Ùˆ ÙÙŠ Ù†ÙˆØ±Ø«Ø§Ù…Ø¨ØªÙˆÙ† Ø¹Ù†ØµØ± Ø¬Ø°Ø¨ ÙƒØ¨ÙŠØ± Ù„Ù„ØµÙˆØ± Ø§Ù„ÙÙˆØªÙˆØºØ±Ø§ÙÙŠØ© Ø®Ù„Ø§Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±. ÙˆÙŠØ¨Ø¯Ùˆ Ø£Ù† Ø§Ù„Ø£Ø®ÙˆØ§Øª Ù†ÙŠØ§Ù… Ø¯ÙŠÙÙŠØŒ Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø«Ù…Ø§Ù†ÙŠ Ø³Ù†ÙˆØ§ØªØŒ ÙˆØ³ÙŠØ§Ø±Ø§ØŒ Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø®Ù…Ø³ Ø³Ù†ÙˆØ§ØªØŒ Ù‚Ø¯ ÙØ§Ø²ØªØ§ Ø¹Ù„Ù‰ Ø£ØµØ¯Ù‚Ø§Ø¦Ù‡Ù…Ø§. Ø´Ø§Ø±Ø¹ Ù†ÙˆÙŠÙ„ØŒ ÙÙŠ Ø¥ÙŠÙ„ÙŠÙ†Ø¬ØŒ Ù„Ù†Ø¯Ù† Ø§Ù„ØºØ±Ø¨ÙŠØ©ØŒ ÙŠØªØ·Ù„Ø¨ Ø§Ù„Ù‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ø®ÙŠØ§Ù„ Ù„ÙƒÙ†Ù‡ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠÙ…ÙƒÙ† Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ Ø´Ø§Ø±Ø¹Ù‹Ø§ ÙŠØ¨Ø¯Ùˆ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ø¥Ø°Ø§ Ù†Ø·Ù‚Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­. Ø±ÙŠÙ†Ø¯ÙŠØ± ÙƒÙ„ÙˆØ² Ø£ÙƒØ«Ø± ÙˆØ¶ÙˆØ­Ù‹Ø§ØŒ ÙˆØ³ÙŠÙƒÙˆÙ† Ù…Ù† Ø§Ù„Ù…Ø¤ÙƒØ¯ Ø£Ù† Ø³ÙƒØ§Ù† Ø´Ø±Ù‚ Ù„Ù†Ø¯Ù† ÙÙŠ Ø­Ø§Ù„Ø© Ù…Ø²Ø§Ø¬ÙŠØ© Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø¨Ø­Ù„ÙˆÙ„ Ø¯ÙŠØ³Ù…Ø¨Ø±. Ø£Ø±Ø¨Ø¹ Ø³Ù†ÙˆØ§Øª Ù…Ù† Ø§Ù„Ø³Ù† Ø¨ÙˆØ¨ÙŠ Ø¬Ø±ÙˆØª ØªÙ„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù…Ø¹ Ø¬Ø¯ØªÙ‡Ø§ Ø¬ÙŠÙ† Ù„ÙˆÙ†Ø¬ Ø¨Ø§Ù„Ù‚Ø±Ø¨ Ù…Ù† Ù…ÙŠØ³ØªÙ„ ØªÙˆ ØºØ±ÙŠÙ† ÙÙŠ Ø£ÙƒØ³ÙÙˆØ±Ø¯. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„ÙÙˆØªÙˆØºØ±Ø§ÙÙŠØ©ØŒ Ù„Ø§ ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ø§Ù„Ù…Ø±Ø­ Ø£ÙƒØ¨Ø± ÙÙŠ Ù„Ù†Ø¯Ù†ØŒ Ø­ÙŠØ« Ø£Ù† Ø§Ù„Ù„Ø§ÙØªØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§ ÙˆÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ Ø¨Ù‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ø­Ù…Ø§Ø³. Ø¨Ø¹Ø¶ Ø§Ù„Ù„Ø§ÙØªØ§Øª Ø§Ù„Ù…ØµÙˆØ±Ø© Ù…Ø«Ù„ Ù†ÙˆÙŠÙ„ Ø±ÙˆØ¯ØŒ Ø§Ù„ØªÙŠ ØªØªØ·Ù„Ø¨ Ù†Ø·Ù‚Ù‹Ø§ Ø®Ø§ØµÙ‹Ø§ØŒ ÙˆØ³ØªØ§Ø± Ø±ÙˆØ¯. Ù„ÙƒÙ† ÙÙŠ Ø­Ø§Ù„Ø§Øª Ø£Ø®Ø±Ù‰ - Ø±ÙŠÙ†Ø¯ÙŠØ± ÙƒÙ„ÙˆØ² ÙˆÙ‡ÙˆÙ„ÙŠ ÙˆØ§ÙŠ - Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù‡Ø±ÙˆØ¨ Ù…Ù† Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…Ø³ÙŠØ­ÙŠ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡. Ù‚Ø¯ ÙŠØ¬Ø°Ø¨ Ø³ØªØ±ÙŠØª ØªÙˆØ±ÙƒÙŠÙ„ Ø§Ù„Ù†Ø§Ø³ ÙÙŠ Ù†ÙˆØ±Ø« Ø¥Ù†Ø¬Ù„Ø§Ù†Ø¯ Ø¥Ù„Ù‰ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ù„ÙƒÙ† Ø¹Ù„ÙŠÙ‡Ù… Ø£Ù† ÙŠØ³Ø§ÙØ±ÙˆØ§ Ø¥Ù„Ù‰ ØªØ§ÙˆØ± Ù‡Ø§Ù…Ù„ØªØ³ Ù„Ø¥ÙŠØ¬Ø§Ø¯ ÙƒØ±Ø§Ù†Ø¨Ø±ÙŠ Ù„ÙŠÙ†. ÙØ±ÙŠØ³ØªÙŠ ÙŠØ§Ø±Ø¯ ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© ÙˆÙŠØ³ØªÙ…Ù†Ø³ØªØ±ØŒ Ù„Ù†Ø¯Ù†ØŒ ØªÙˆÙØ± Ø§Ø³Ù…Ù‹Ø§ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ù…Ø¹ Ø®Ù„ÙÙŠØ© Ø£ÙƒØ«Ø± ØªÙˆØ±Ø§ØªÙŠØ©. ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø£ÙˆÙ„Ø¦Ùƒ Ø§Ù„Ø°ÙŠÙ† Ù„Ø§ ÙŠØ³ØªÙ…ØªØ¹ÙˆÙ† Ø¨Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø£Ù† ÙŠØ¨ØªØ¹Ø¯ÙˆØ§ Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø´ÙˆØ§Ø±Ø¹. ÙˆØ¨Ø§Ù„Ù…Ø«Ù„ØŒ Ø¥Ø°Ø§ ÙƒÙ†Øª Ù„Ø§ ØªØ´Ø¹Ø± Ø¨Ø§Ù„Ø±ØºØ¨Ø© ÙÙŠ Ù‚Ø¨Ù„Ø© Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ ÙØªØ¹Ù„Ù… Ù…Ù† Ø£Ø®Ø·Ø§Ø¡ Ø¨ÙˆØ¨ÙŠ Ø¬Ø±ÙˆØª Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø£Ø±Ø¨Ø¹ Ø³Ù†ÙˆØ§ØªØŒ Ø§Ù„ØªÙŠ Ø§Ø´ØªØ¹Ù„Øª ÙˆÙ‡ÙŠ ØªÙ„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù…Ø¹ Ø¬Ø¯ØªÙ‡Ø§ØŒ Ø¬ÙŠÙ† Ù„ÙˆÙ†Ø¬ØŒ Ø£Ù…Ø§Ù… Ù…ÙŠØ³ØªÙ„ ØºØ±ÙŠÙ† ÙÙŠ Ø£ÙƒØ³ÙÙˆØ±Ø¯. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø³ÙƒØ§Ù† Ø£Ø¯ÙÙ†Øª ÙˆØ§ÙŠØŒ Ø¯ÙŠØ³Ù…Ø¨Ø± Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ£ØªÙŠ Ø¨Ø³Ø±Ø¹Ø© ÙƒØ§ÙÙŠØ©. Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† ÙƒÙ„ Ø´ÙŠØ¡ØŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠ Ù†ÙˆÙŠØ³Ù„ÙŠÙ† ÙÙŠ Ù†ÙˆØ±Ø«Ù„ÙŠÙ†ÙƒÙˆÙ„Ù†ØŒ Ø¥Ù„ÙŠÙ†Ø¬ØŒ Ø´Ø§Ø±Ø¹ Ù…Ù†Ø§Ø³Ø¨ Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ .', 'role': 'user'}, {'content': 'ÙˆØ¬Ø¯ Ø¨Ø­Ø« Ø£Ø¬Ø±Ø§Ù‡ Ù…ÙˆØ¸ÙÙˆ \"Ø±ÙˆÙŠØ§Ù„ Ù…ÙŠÙ„\" Ø§Ù„Ø¹Ø§Ù… Ø§Ù„Ù…Ø§Ø¶ÙŠ Ø£Ù† Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø© Ù„Ø¯ÙŠÙ‡Ø§ 3369 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ù…ÙÙˆÙŽØ¶ÙˆØ¹Ù‡Ø§ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯. ÙˆÙŠØ¹Ø¯ \"Ù‡ÙˆÙ„ÙŠ Ø³ØªØ±ÙŠØª\" Ø£ÙƒØ«Ø± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´ÙˆØ§Ø±Ø¹ Ø§Ø­ØªÙØ§Ù„ÙŠØ© Ø´ÙŠÙˆØ¹Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. Ù‡Ù†Ø§Ùƒ 990 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©.', 'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "print(\"ðŸ“¥ Loading SFT dataset...\")\n",
        "train_dataset_sft = load_dataset(\"oddadmix/arabic-news-summarization\", split=\"train\")\n",
        "eval_dataset_sft = load_dataset(\"oddadmix/arabic-news-summarization\", split=\"test\")\n",
        "\n",
        "\n",
        "def filterEmpty(example):\n",
        "    if example[\"summary_text_translated\"] is None or example[\"origin_text_translated\"] is None:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "train_dataset_sft = train_dataset_sft.filter(filterEmpty)\n",
        "eval_dataset_sft = eval_dataset_sft.filter(filterEmpty)\n",
        "\n",
        "\n",
        "def convert_to_conversation(example):\n",
        "    example[\"messages\"] = [\n",
        "        {\n",
        "        \"content\": \"Summarize the following text: \\n\\n \" + example[\"origin_text_translated\"] ,\n",
        "        \"role\": \"user\"\n",
        "        },\n",
        "        {\n",
        "        \"content\": example[\"summary_text_translated\"],\n",
        "        \"role\": \"assistant\"\n",
        "        }\n",
        "        ]\n",
        "    return example\n",
        "\n",
        "train_dataset_sft = train_dataset_sft.map(convert_to_conversation, remove_columns=[\"origin_text_translated\", \"origin_text\", \"summary_text_translated\",\"summary_text\"])\n",
        "eval_dataset_sft = eval_dataset_sft.map(convert_to_conversation, remove_columns=[\"origin_text_translated\", \"origin_text\", \"summary_text_translated\",\"summary_text\"])\n",
        "\n",
        "print(\"âœ… SFT Dataset loaded:\")\n",
        "print(f\"   ðŸ“š Train samples: {len(train_dataset_sft)}\")\n",
        "print(f\"   ðŸ§ª Eval samples: {len(eval_dataset_sft)}\")\n",
        "print(f\"\\nðŸ“ Single Sample: {train_dataset_sft[0]['messages']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5pI5JWpIlFQ"
      },
      "source": [
        "## Launch Training\n",
        "\n",
        "We are now ready to launch an SFT run with `SFTTrainer`, feel free to modify `SFTConfig` to play around with different configurations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixD8Po-eAbPp",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "eeafa9bf-3976-4b17-b64c-68f4ae4ff808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ—ï¸  Creating SFT trainer...\n",
            "\n",
            "ðŸš€ Starting SFT training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='5954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  25/5954 01:10 < 5:01:38, 0.33 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTConfig, SFTTrainer\n",
        "\n",
        "sft_config = SFTConfig(\n",
        "    output_dir=\"./lfm2-sft-summary\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=3,\n",
        "    learning_rate=5e-5,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_steps=100,\n",
        "    warmup_ratio=0.2,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=None,\n",
        "    bf16=False # <- not all colab GPUs support bf16\n",
        ")\n",
        "\n",
        "print(\"ðŸ—ï¸  Creating SFT trainer...\")\n",
        "sft_trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=sft_config,\n",
        "    train_dataset=train_dataset_sft,\n",
        "    eval_dataset=eval_dataset_sft,\n",
        "    processing_class=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"\\nðŸš€ Starting SFT training...\")\n",
        "sft_trainer.train()\n",
        "\n",
        "print(\"ðŸŽ‰ SFT training completed!\")\n",
        "\n",
        "sft_trainer.push_to_hub(\"oddadmix/arabic-summarization_test\")\n",
        "#sft_trainer.save_model()\n",
        "print(f\"ðŸ’¾ SFT model saved to: {sft_config.output_dir}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}