{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3PTFH-H9Ozk"
   },
   "source": [
    "# ðŸ’§ LFM2 - SFT with TRL\n",
    "\n",
    "This tutorial demonstrates how to fine-tune our LFM2 models, e.g. [`LiquidAI/LFM2-1.2B`](https://huggingface.co/LiquidAI/LFM2-1.2B), using the TRL library.\n",
    "\n",
    "Follow along if it's your first time using trl, or take single code snippets for your own workflow\n",
    "\n",
    "## ðŸŽ¯ What you'll find:\n",
    "- **SFT** (Supervised Fine-Tuning) - Basic instruction following\n",
    "- **LoRA + SFT** - Using LoRA (from PEFT) to SFT while on constrained hardware\n",
    "\n",
    "## ðŸ“‹ Prerequisites:\n",
    "- **GPU Runtime**: Select GPU in `Runtime` â†’ `Change runtime type`\n",
    "- **Hugging Face Account**: For accessing models and datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0RPLu2h9ome"
   },
   "source": [
    "# ðŸ“¦ Installation & Setup\n",
    "\n",
    "First, let's install all the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FIcp_wo9nsR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.54.1 trl>=0.18.2 peft>=0.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install patchelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!patchelf --add-rpath '$ORIGIN/../../nvidia/cusparse/lib' /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41UEf1uxCd6m"
   },
   "source": [
    "Let's now verify the packages are installed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSJgYtHT_Os4",
    "outputId": "23f86c62-471c-4579-fc23-1df88e87698b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import trl\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "print(f\"ðŸ“¦ PyTorch version: {torch.__version__}\")\n",
    "print(f\"ðŸ¤— Transformers version: {transformers.__version__}\")\n",
    "print(f\"ðŸ“Š TRL version: {trl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_uXLzxQ_rnK"
   },
   "source": [
    "# Loading the model from Transformers ðŸ¤—\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iA3erKM4-HhS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š Loading tokenizer...\n",
      "ðŸ§  Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.11/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-08-19 00:26:28.995179: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-19 00:26:29.033924: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-19 00:26:29.033969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-19 00:26:29.035101: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-19 00:26:29.042173: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-19 00:26:29.962824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Local model loaded successfully!\n",
      "ðŸ”¢ Parameters: 354,483,968\n",
      "ðŸ“– Vocab size: 64400\n",
      "ðŸ’¾ Model size: ~0.7 GB (bfloat16)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import torch\n",
    "\n",
    "model_id = \"LiquidAI/LFM2-350M\" # <- or LFM2-700M or LFM2-350M\n",
    "\n",
    "print(\"ðŸ“š Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(\"ðŸ§  Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"bfloat16\",\n",
    "#   attn_implementation=\"flash_attention_2\" <- uncomment on compatible GPU\n",
    ")\n",
    "\n",
    "print(\"âœ… Local model loaded successfully!\")\n",
    "print(f\"ðŸ”¢ Parameters: {model.num_parameters():,}\")\n",
    "print(f\"ðŸ“– Vocab size: {len(tokenizer)}\")\n",
    "print(f\"ðŸ’¾ Model size: ~{model.num_parameters() * 2 / 1e9:.1f} GB (bfloat16)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ABA6Yrm_lql"
   },
   "source": [
    "# ðŸŽ¯ Part 1: Supervised Fine-Tuning (SFT)\n",
    "\n",
    "SFT teaches the model to follow instructions by training on input-output pairs (instruction vs response). This is the foundation for creating instruction-following models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KufdgeypHtst"
   },
   "source": [
    "## Load an SFT Dataset\n",
    "\n",
    "We will use [HuggingFaceTB/smoltalk](https://huggingface.co/datasets/HuggingFaceTB/smoltalk), limiting ourselves to the first 5k samples for brevity. Feel free to change the limit by changing the slicing index in the parameter `split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XCe8O06-_Cps",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading SFT dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f49b719f5f4528bebae99c4c81ae18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/716 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f5230f2b4341a29b74697578722896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/92.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b97ee6327f446718d444df1e8854ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/928k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b95e6f022b416aa8011112366811d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813d3db99d7a4d06b7f65ea8512f8095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd9f894c8184189bcfcb53b6e9fcf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d2ff96d0ba4d7eba593847ec10957d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be362032b9b041b0b891894ff43e1f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e634f73d4f472f898fb072ac479ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SFT Dataset loaded:\n",
      "   ðŸ“š Train samples: 17862\n",
      "   ðŸ§ª Eval samples: 181\n",
      "\n",
      "ðŸ“ Single Sample: [{'content': 'Summarize the following text: \\n\\n Ø¨Ù‚Ù„Ù…: ÙˆÙ„ÙŠØ§Ù… ØªÙˆØ±ÙÙŠÙ„. Ù†Ø´Ø± ÙÙŠ: 08:04 ØµØ¨Ø§Ø­Ù‹Ø§ Ø¨ØªÙˆÙ‚ÙŠØª Ø´Ø±Ù‚ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©ØŒ 21 Ø¯ÙŠØ³Ù…Ø¨Ø± 2013 | ØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡: 09:07 ØµØ¨Ø§Ø­Ù‹Ø§ Ø¨ØªÙˆÙ‚ÙŠØª Ø´Ø±Ù‚ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©ØŒ 21 Ø¯ÙŠØ³Ù…Ø¨Ø± 2013. Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¯Ø®Ù„ ÙÙŠ Ø§Ù„Ø±ÙˆØ­ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø¨Ù…Ø¬Ø±Ø¯ Ø³Ù…Ø§Ø¹ Ø£ØºÙ†ÙŠØ© Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø£Ùˆ Ø±Ø¤ÙŠØ© ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ø²Ø®Ø§Ø±Ù Ù„Ù„Ø¨ÙŠØ¹ØŒ ÙÙ…Ù† Ø§Ù„Ø£ÙØ¶Ù„ Ø£Ù† ØªØ¨ØªØ¹Ø¯ Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø´ÙˆØ§Ø±Ø¹. Ù‚Ø¯ ØªØ¨Ø¯Ùˆ Ø´ÙˆØ§Ø±Ø¹ Ù…Ø«Ù„ ØªÙŠÙ†Ø³ÙŠÙ„ Ù„ÙŠÙ† ÙÙŠ Ù†ÙˆÙ†ÙŠØªÙˆÙ†ØŒ ÙˆØ§Ø±ÙˆÙŠÙƒØ´Ø§ÙŠØ±ØŒ ØºØ±ÙŠØ¨Ø© ÙÙŠ Ø§Ù„ØµÙŠÙ - Ù„ÙƒÙ†Ù‡Ø§ ØªØ£Ø®Ø° Ù…ÙƒØ§Ù†Ù‡Ø§ ÙÙŠ Ø¯ÙŠØ³Ù…Ø¨Ø±. ÙˆØ¬Ø¯ Ø¨Ø­Ø« Ù…ÙˆØ¸ÙÙŠ Ø±ÙˆÙŠØ§Ù„ Ù…ÙŠÙ„ Ø£Ù† Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø© Ù„Ø¯ÙŠÙ‡Ø§ 3369 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ø§Ø³Ù… Ø´Ø§Ø±Ø¹ ÙÙŠ Ø§Ù„Ø¨Ù„Ø§Ø¯. ØªÙŠÙ†Ø³ÙŠÙ„ Ù„ÙŠÙ† ÙÙŠ Ù†ÙˆÙ†ÙŠØªÙˆÙ†ØŒ ÙˆØ§Ø±ÙˆÙŠÙƒØ´Ø§ÙŠØ±ØŒ Ù…Ø²ÙŠÙ†Ø© Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ø³ÙƒØ§Ù† Ù…ÙŠØ´ÙŠÙ„ Ø£ÙˆØ±ØªÙˆÙ† ÙˆØ§Ø¨Ù†Ù‡Ø§ Ø°ÙŠ Ø§Ù„Ø«Ù„Ø§Ø« Ø³Ù†ÙˆØ§ØªØŒ Ù…Ø§Ø«ÙŠÙˆ. ØªØ¹Ø±Ø¶ Ø§Ù„Ø£Ø®ÙˆØ§Øª Ù†ÙŠØ§Ù… Ø¯ÙŠÙÙŠ (Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±)ØŒ Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø«Ù…Ø§Ù†ÙŠ Ø³Ù†ÙˆØ§ØªØŒ ÙˆØ³ÙŠØ§Ø±Ø§ Ø¯ÙŠÙÙŠØŒ Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø®Ù…Ø³ Ø³Ù†ÙˆØ§ØªØŒ Ø£Ù…Ø§Ù… Ø§Ø³Ù… Ø´Ø§Ø±Ø¹Ù‡Ù… - Ø§Ù„Ø°ÙŠ Ù‚Ø¯ ÙŠØ¨Ø¯Ùˆ ØºØ±ÙŠØ¨Ù‹Ø§ Ø¨Ø¹Ø¶ Ø§Ù„Ø´ÙŠØ¡ ÙÙŠ Ø§Ù„ØµÙŠÙ - ÙÙŠ Ù†ÙˆØ±Ø«Ø§Ù…Ø¨ØªÙˆÙ†. Ù‡ÙˆÙ„ÙŠ Ø³ØªØ±ÙŠØª Ù‡ÙŠ Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø´ÙŠÙˆØ¹Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. Ù‡Ù†Ø§Ùƒ 990 Ø§Ø³Ù…Ù‹Ø§ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ø´ÙˆØ§Ø±Ø¹ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. 1. Ø´Ø§Ø±Ø¹ Ù‡ÙˆÙ„ÙŠ. 2. Ø´Ø§Ø±Ø¹ Ø¨ÙŠÙ„. 3. Ø´Ø§Ø±Ø¹ Ù…Ø§Ø±ÙŠ. 4. Ø´Ø§Ø±Ø¹ Ø¥Ù†Ø¬Ù„. 5. Ø·Ø±ÙŠÙ‚ Ø³ØªØ§Ø±. 6. Ø´Ø§Ø±Ø¹ Ø¨Ùˆ. 7. Ø³Ø§Ø­Ø© ÙÙŠØ³ØªÙŠÙØ§Ù„. 8. Ø´Ø§Ø±Ø¹ Ù†ÙˆÙŠÙ„. 9. Ø´Ø§Ø±Ø¹ ØºÙˆÙ„Ø¯. 10. Ø´Ø§Ø±Ø¹ ØºØ§Ø±Ù„Ø§Ù†Ø¯. ÙƒØ´Ù Ø§Ù„Ø¨Ø­Ø« Ø£ÙŠØ¶Ù‹Ø§ Ø£Ù† Ø¥Ù‚Ù„ÙŠÙ… Ù…ÙŠØ¯Ù„Ø§Ù†Ø¯Ø² Ù„Ø¯ÙŠÙ‡ Ù…Ø§ Ù…Ø¬Ù…ÙˆØ¹Ù‡ 560 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ø£ÙƒØ«Ø± Ù…Ù† Ø£ÙŠ Ù…Ù†Ø·Ù‚Ø© Ø£Ø®Ø±Ù‰ ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. ØªØ­ØªÙˆÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø§ Ù…Ø¬Ù…ÙˆØ¹Ù‡ 560 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ ÙˆØªØªÙ…ØªØ¹ Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø´ÙˆØ§Ø±Ø¹ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ù…Ø«Ù„ Ø±ÙŠÙ†Ø¯ÙŠØ± Ø±ÙˆØ¯ØŒ ÙˆÙ†ÙˆÙŠÙ„ Ø±ÙˆØ¯ØŒ ÙˆØ¨ÙŠÙ„ ÙƒÙ„ÙˆØ²ØŒ ÙˆÙ‡ÙˆÙ„ÙŠ Ø³ØªØ±ÙŠØª. Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø¬Ø§Ø¡Øª Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø±ÙˆÙŠØ§Ù„ Ù…ÙŠÙ„ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 29 Ù…Ù„ÙŠÙˆÙ† Ø¹Ù†ÙˆØ§Ù† ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. ØªÙƒØ´Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙŠØ¶Ù‹Ø§ Ø¹Ù† Ø­Ø¨Ù†Ø§ Ù„Ø±Ù†ÙˆØ¯ Ø³Ø§Ù†ØªØ§ØŒ Ø­ÙŠØ« Ø£Ù† Ø³Ø¨Ø¹Ø© Ù…Ù† ØªØ³Ø¹Ø© Ø±Ù†ÙˆØ¯ Ù…Ù…Ø«Ù„Ø© ÙÙŠ Ø§Ø³Ù… Ø´Ø§Ø±Ø¹. ÙˆØªØ´Ù…Ù„ Ù‡Ø°Ù‡: Ø¯Ø§Ø´Ø±ØŒ ÙˆØ¯Ø§Ù†Ø³Ø±ØŒ ÙˆÙÙŠÙƒØ³Ù†ØŒ ÙˆÙƒÙˆÙ…ÙŠØªØŒ ÙˆÙƒÙŠÙˆØ¨ÙŠØ¯ØŒ ÙˆØ¯ÙˆÙ†Ø±ØŒ ÙˆØ±ÙˆØ¯ÙˆÙ„Ù. Ø³ÙƒØ§Ù† ØªÙŠÙ†Ø³ÙŠÙ„ Ù„ÙŠÙ† ÙÙŠ Ù†ÙˆÙ†ÙŠØªÙˆÙ†ØŒ Ù†ÙˆØ±Ø«Ø§Ù…Ø¨ØªÙˆÙ†ØŒ Ø¨Ø°Ù„ÙˆØ§ Ø¬Ù‡Ø¯Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ²ÙŠÙŠÙ† Ù„Ø§ÙØªØªÙ‡Ù… Ù…Ø«Ù„ Ø´Ø¬Ø±Ø© Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯. Ù‚Ø¯Ù… Ù…Ø§Ø«ÙŠÙˆ Ø§Ù„Ø¨Ø§Ù„Øº Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø«Ù„Ø§Ø« Ø³Ù†ÙˆØ§Øª ÙˆØ£Ù…Ù‡ Ù…ÙŠØ´ÙŠÙ„ Ø£ÙˆØ±ØªÙˆÙ† Ø¨Ø§Ù„ÙØ¹Ù„ Ù„ØªØ²ÙŠÙŠÙ† Ù„Ø§ÙØªØ© Ø´Ø§Ø±Ø¹Ù‡Ù…. ÙÙŠ ØºØ¶ÙˆÙ† Ø°Ù„ÙƒØŒ Ø³ÙŠÙƒÙˆÙ† ÙØ±ÙŠØ³ØªÙŠ Ù‡ÙˆÙ„Ùˆ ÙÙŠ Ù†ÙˆØ±Ø«Ø§Ù…Ø¨ØªÙˆÙ† Ø¹Ù†ØµØ± Ø¬Ø°Ø¨ ÙƒØ¨ÙŠØ± Ù„Ù„ØµÙˆØ± Ø§Ù„ÙÙˆØªÙˆØºØ±Ø§ÙÙŠØ© Ø®Ù„Ø§Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±. ÙˆÙŠØ¨Ø¯Ùˆ Ø£Ù† Ø§Ù„Ø£Ø®ÙˆØ§Øª Ù†ÙŠØ§Ù… Ø¯ÙŠÙÙŠØŒ Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø«Ù…Ø§Ù†ÙŠ Ø³Ù†ÙˆØ§ØªØŒ ÙˆØ³ÙŠØ§Ø±Ø§ØŒ Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø®Ù…Ø³ Ø³Ù†ÙˆØ§ØªØŒ Ù‚Ø¯ ÙØ§Ø²ØªØ§ Ø¹Ù„Ù‰ Ø£ØµØ¯Ù‚Ø§Ø¦Ù‡Ù…Ø§. Ø´Ø§Ø±Ø¹ Ù†ÙˆÙŠÙ„ØŒ ÙÙŠ Ø¥ÙŠÙ„ÙŠÙ†Ø¬ØŒ Ù„Ù†Ø¯Ù† Ø§Ù„ØºØ±Ø¨ÙŠØ©ØŒ ÙŠØªØ·Ù„Ø¨ Ø§Ù„Ù‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ø®ÙŠØ§Ù„ Ù„ÙƒÙ†Ù‡ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠÙ…ÙƒÙ† Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ Ø´Ø§Ø±Ø¹Ù‹Ø§ ÙŠØ¨Ø¯Ùˆ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ø¥Ø°Ø§ Ù†Ø·Ù‚Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­. Ø±ÙŠÙ†Ø¯ÙŠØ± ÙƒÙ„ÙˆØ² Ø£ÙƒØ«Ø± ÙˆØ¶ÙˆØ­Ù‹Ø§ØŒ ÙˆØ³ÙŠÙƒÙˆÙ† Ù…Ù† Ø§Ù„Ù…Ø¤ÙƒØ¯ Ø£Ù† Ø³ÙƒØ§Ù† Ø´Ø±Ù‚ Ù„Ù†Ø¯Ù† ÙÙŠ Ø­Ø§Ù„Ø© Ù…Ø²Ø§Ø¬ÙŠØ© Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø¨Ø­Ù„ÙˆÙ„ Ø¯ÙŠØ³Ù…Ø¨Ø±. Ø£Ø±Ø¨Ø¹ Ø³Ù†ÙˆØ§Øª Ù…Ù† Ø§Ù„Ø³Ù† Ø¨ÙˆØ¨ÙŠ Ø¬Ø±ÙˆØª ØªÙ„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù…Ø¹ Ø¬Ø¯ØªÙ‡Ø§ Ø¬ÙŠÙ† Ù„ÙˆÙ†Ø¬ Ø¨Ø§Ù„Ù‚Ø±Ø¨ Ù…Ù† Ù…ÙŠØ³ØªÙ„ ØªÙˆ ØºØ±ÙŠÙ† ÙÙŠ Ø£ÙƒØ³ÙÙˆØ±Ø¯. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„ÙÙˆØªÙˆØºØ±Ø§ÙÙŠØ©ØŒ Ù„Ø§ ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ø§Ù„Ù…Ø±Ø­ Ø£ÙƒØ¨Ø± ÙÙŠ Ù„Ù†Ø¯Ù†ØŒ Ø­ÙŠØ« Ø£Ù† Ø§Ù„Ù„Ø§ÙØªØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§ ÙˆÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ Ø¨Ù‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ø­Ù…Ø§Ø³. Ø¨Ø¹Ø¶ Ø§Ù„Ù„Ø§ÙØªØ§Øª Ø§Ù„Ù…ØµÙˆØ±Ø© Ù…Ø«Ù„ Ù†ÙˆÙŠÙ„ Ø±ÙˆØ¯ØŒ Ø§Ù„ØªÙŠ ØªØªØ·Ù„Ø¨ Ù†Ø·Ù‚Ù‹Ø§ Ø®Ø§ØµÙ‹Ø§ØŒ ÙˆØ³ØªØ§Ø± Ø±ÙˆØ¯. Ù„ÙƒÙ† ÙÙŠ Ø­Ø§Ù„Ø§Øª Ø£Ø®Ø±Ù‰ - Ø±ÙŠÙ†Ø¯ÙŠØ± ÙƒÙ„ÙˆØ² ÙˆÙ‡ÙˆÙ„ÙŠ ÙˆØ§ÙŠ - Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù‡Ø±ÙˆØ¨ Ù…Ù† Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…Ø³ÙŠØ­ÙŠ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡. Ù‚Ø¯ ÙŠØ¬Ø°Ø¨ Ø³ØªØ±ÙŠØª ØªÙˆØ±ÙƒÙŠÙ„ Ø§Ù„Ù†Ø§Ø³ ÙÙŠ Ù†ÙˆØ±Ø« Ø¥Ù†Ø¬Ù„Ø§Ù†Ø¯ Ø¥Ù„Ù‰ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ù„ÙƒÙ† Ø¹Ù„ÙŠÙ‡Ù… Ø£Ù† ÙŠØ³Ø§ÙØ±ÙˆØ§ Ø¥Ù„Ù‰ ØªØ§ÙˆØ± Ù‡Ø§Ù…Ù„ØªØ³ Ù„Ø¥ÙŠØ¬Ø§Ø¯ ÙƒØ±Ø§Ù†Ø¨Ø±ÙŠ Ù„ÙŠÙ†. ÙØ±ÙŠØ³ØªÙŠ ÙŠØ§Ø±Ø¯ ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© ÙˆÙŠØ³ØªÙ…Ù†Ø³ØªØ±ØŒ Ù„Ù†Ø¯Ù†ØŒ ØªÙˆÙØ± Ø§Ø³Ù…Ù‹Ø§ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ù…Ø¹ Ø®Ù„ÙÙŠØ© Ø£ÙƒØ«Ø± ØªÙˆØ±Ø§ØªÙŠØ©. ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø£ÙˆÙ„Ø¦Ùƒ Ø§Ù„Ø°ÙŠÙ† Ù„Ø§ ÙŠØ³ØªÙ…ØªØ¹ÙˆÙ† Ø¨Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø£Ù† ÙŠØ¨ØªØ¹Ø¯ÙˆØ§ Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø´ÙˆØ§Ø±Ø¹. ÙˆØ¨Ø§Ù„Ù…Ø«Ù„ØŒ Ø¥Ø°Ø§ ÙƒÙ†Øª Ù„Ø§ ØªØ´Ø¹Ø± Ø¨Ø§Ù„Ø±ØºØ¨Ø© ÙÙŠ Ù‚Ø¨Ù„Ø© Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ ÙØªØ¹Ù„Ù… Ù…Ù† Ø£Ø®Ø·Ø§Ø¡ Ø¨ÙˆØ¨ÙŠ Ø¬Ø±ÙˆØª Ø§Ù„Ø¨Ø§Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¹Ù…Ø± Ø£Ø±Ø¨Ø¹ Ø³Ù†ÙˆØ§ØªØŒ Ø§Ù„ØªÙŠ Ø§Ø´ØªØ¹Ù„Øª ÙˆÙ‡ÙŠ ØªÙ„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù…Ø¹ Ø¬Ø¯ØªÙ‡Ø§ØŒ Ø¬ÙŠÙ† Ù„ÙˆÙ†Ø¬ØŒ Ø£Ù…Ø§Ù… Ù…ÙŠØ³ØªÙ„ ØºØ±ÙŠÙ† ÙÙŠ Ø£ÙƒØ³ÙÙˆØ±Ø¯. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø³ÙƒØ§Ù† Ø£Ø¯ÙÙ†Øª ÙˆØ§ÙŠØŒ Ø¯ÙŠØ³Ù…Ø¨Ø± Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ£ØªÙŠ Ø¨Ø³Ø±Ø¹Ø© ÙƒØ§ÙÙŠØ©. Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† ÙƒÙ„ Ø´ÙŠØ¡ØŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠ Ù†ÙˆÙŠØ³Ù„ÙŠÙ† ÙÙŠ Ù†ÙˆØ±Ø«Ù„ÙŠÙ†ÙƒÙˆÙ„Ù†ØŒ Ø¥Ù„ÙŠÙ†Ø¬ØŒ Ø´Ø§Ø±Ø¹ Ù…Ù†Ø§Ø³Ø¨ Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ .', 'role': 'user'}, {'content': 'ÙˆØ¬Ø¯ Ø¨Ø­Ø« Ø£Ø¬Ø±Ø§Ù‡ Ù…ÙˆØ¸ÙÙˆ \"Ø±ÙˆÙŠØ§Ù„ Ù…ÙŠÙ„\" Ø§Ù„Ø¹Ø§Ù… Ø§Ù„Ù…Ø§Ø¶ÙŠ Ø£Ù† Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø© Ù„Ø¯ÙŠÙ‡Ø§ 3369 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ù…ÙÙˆÙŽØ¶ÙˆØ¹Ù‡Ø§ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯. ÙˆÙŠØ¹Ø¯ \"Ù‡ÙˆÙ„ÙŠ Ø³ØªØ±ÙŠØª\" Ø£ÙƒØ«Ø± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´ÙˆØ§Ø±Ø¹ Ø§Ø­ØªÙØ§Ù„ÙŠØ© Ø´ÙŠÙˆØ¹Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. Ù‡Ù†Ø§Ùƒ 990 Ø§Ø³Ù…Ù‹Ø§ Ù„Ø´ÙˆØ§Ø±Ø¹ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©.', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"ðŸ“¥ Loading SFT dataset...\")\n",
    "train_dataset_sft = load_dataset(\"oddadmix/arabic-news-summarization\", split=\"train\")\n",
    "eval_dataset_sft = load_dataset(\"oddadmix/arabic-news-summarization\", split=\"test\")\n",
    "\n",
    "\n",
    "def filterEmpty(example):\n",
    "    if example[\"summary_text_translated\"] is None or example[\"origin_text_translated\"] is None: \n",
    "        return False\n",
    "    return True\n",
    "\n",
    "train_dataset_sft = train_dataset_sft.filter(filterEmpty)\n",
    "eval_dataset_sft = eval_dataset_sft.filter(filterEmpty)\n",
    "\n",
    "\n",
    "def convert_to_conversation(example):\n",
    "    example[\"messages\"] = [\n",
    "        {\n",
    "        \"content\": \"Summarize the following text: \\n\\n \" + example[\"origin_text_translated\"] ,\n",
    "        \"role\": \"user\"\n",
    "        },\n",
    "        {\n",
    "        \"content\": example[\"summary_text_translated\"],\n",
    "        \"role\": \"assistant\"\n",
    "        }\n",
    "        ]\n",
    "    return example\n",
    "\n",
    "train_dataset_sft = train_dataset_sft.map(convert_to_conversation, remove_columns=[\"origin_text_translated\", \"origin_text\", \"summary_text_translated\",\"summary_text\"])\n",
    "eval_dataset_sft = eval_dataset_sft.map(convert_to_conversation, remove_columns=[\"origin_text_translated\", \"origin_text\", \"summary_text_translated\",\"summary_text\"])\n",
    "\n",
    "print(\"âœ… SFT Dataset loaded:\")\n",
    "print(f\"   ðŸ“š Train samples: {len(train_dataset_sft)}\")\n",
    "print(f\"   ðŸ§ª Eval samples: {len(eval_dataset_sft)}\")\n",
    "print(f\"\\nðŸ“ Single Sample: {train_dataset_sft[0]['messages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5pI5JWpIlFQ"
   },
   "source": [
    "## Launch Training\n",
    "\n",
    "We are now ready to launch an SFT run with `SFTTrainer`, feel free to modify `SFTConfig` to play around with different configurations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixD8Po-eAbPp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—ï¸  Creating SFT trainer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfa2b44e9cc4428bb62a6a39e817602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25baa87e24c241cc886483fef226acd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/17862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a65ade53ce04f6cb1300e614b8be2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bd5a17940f4ad0a3c323fc58c961cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-19 00:27:18,883] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\n",
      "ðŸš€ Starting SFT training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahmed-m-wasfy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/Translations/wandb/run-20250819_002721-cl4p100g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahmed-m-wasfy/huggingface/runs/cl4p100g' target=\"_blank\">./lfm2-sft-summary</a></strong> to <a href='https://wandb.ai/ahmed-m-wasfy/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahmed-m-wasfy/huggingface' target=\"_blank\">https://wandb.ai/ahmed-m-wasfy/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahmed-m-wasfy/huggingface/runs/cl4p100g' target=\"_blank\">https://wandb.ai/ahmed-m-wasfy/huggingface/runs/cl4p100g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4697' max='11170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4697/11170 02:42 < 1:17:21, 1.39 it/s, Epoch 4.20/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./lfm2-sft-summary\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=100,\n",
    "    warmup_ratio=0.2,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=None,\n",
    "    bf16=False # <- not all colab GPUs support bf16\n",
    ")\n",
    "\n",
    "print(\"ðŸ—ï¸  Creating SFT trainer...\")\n",
    "sft_trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_dataset_sft,\n",
    "    eval_dataset=eval_dataset_sft,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"\\nðŸš€ Starting SFT training...\")\n",
    "sft_trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "print(\"ðŸŽ‰ SFT training completed!\")\n",
    "\n",
    "sft_trainer.push_to_hub(\"oddadmix/arabic-summarization\")\n",
    "#sft_trainer.save_model()\n",
    "print(f\"ðŸ’¾ SFT model saved to: {sft_config.output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
